{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "025b6785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7ad671",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {'and': ['&', \"'n\"], '': ['%', ',', '.', '#', '[', ']', '!', '?']}\n",
    "    \n",
    "def clean_instruction(instruction):\n",
    "    instruction = instruction.lower()\n",
    "    for rep, char_list in replace_dict.items():\n",
    "        for c_ in char_list:\n",
    "            if c_ in instruction:\n",
    "                instruction = instruction.replace(c_, rep)\n",
    "        instruction = instruction.strip()\n",
    "    \n",
    "    # remove sentences starting with \"1.\", \"2.\", ... from the targets\n",
    "    if len(instruction) > 0 and instruction[0].isdigit():\n",
    "        instruction = ''\n",
    "    return instruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b01762b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "bos_token = \"<BOS>\"\n",
    "eos_token = \"<EOS>\"\n",
    "pad_token = \"<PAD>\"\n",
    "\n",
    "ingrs_start = \"<INGRS_START>\"\n",
    "ingrs_end = \"<INGRS_END>\"\n",
    "ingrs_next = \"<INGRS_NEXT>\"\n",
    "instr_start = \"<INSTR_START>\"\n",
    "instr_end = \"<INSTR_END>\"\n",
    "instr_next = \"<INSTR_NEXT>\"\n",
    "title_start = \"<TITLE_START>\"\n",
    "title_end = \"<TITLE_END>\"\n",
    "\n",
    "\n",
    "special_tokens = [ingrs_start, ingrs_end, ingrs_next, instr_start, instr_end, instr_next, title_start, title_end]\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "    \"gpt2\", \n",
    "    additional_special_tokens=special_tokens, \n",
    "    bos_token=bos_token,\n",
    "    eos_token=eos_token,\n",
    "    pad_token=pad_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09fb0c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a7caeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_seq(df):\n",
    "#     seq = []\n",
    "    \n",
    "#     for i, row in tqdm(df.iterrows()):\n",
    "#         seq.append(build_sequence(row))\n",
    "    \n",
    "#     return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02fc9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"./dataset/new_merged/test_merged.csv\")\n",
    "# train_df = pd.read_csv(\"./dataset/new_merged/train_merged.csv\")\n",
    "# val_df = pd.read_csv(\"./dataset/new_merged/val_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d31c9d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_seq = get_seq(train_df)\n",
    "# val_seq = get_seq(val_df)\n",
    "# test_seq = get_seq(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a89bb957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(test_df, open('./test_seq.pkl', 'wb'))\n",
    "# pickle.dump(train_df, open('./train_seq.pkl', 'wb'))\n",
    "# pickle.dump(val_df, open('./val_seq.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "355fad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.save_vocabulary(\"./\", \"recipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fca86917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 11:30:06.094975: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-09 11:30:06.095029: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Model, TrainingArguments\n",
    "\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "training_args = TrainingArguments(output_dir=\"./checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16bfd049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(row):\n",
    "    title = row[\"title\"]\n",
    "    ingrs = \" \".join(row[\"base_ingrs\"].split(\";\"))\n",
    "    instructions = f\"{instr_next}\".join([clean_instruction(inst) for inst in row[\"instructions\"].split(\";\")])\n",
    "    \n",
    "    seq = f\"{bos_token}{ingrs_start}{ingrs}{ingrs_end}{instr_start}{instructions}{instr_end}{title_start}{title}{title_end}{eos_token}\"\n",
    "    tkns = tokenizer(seq, truncation=True)\n",
    "\n",
    "    return tkns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed0ce8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(test_df)\n",
    "tokenized_train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    num_proc=4,\n",
    "    remove_columns=list(test_df.columns)\n",
    ")\n",
    "\n",
    "# train_dataset = Dataset.from_pandas(val_df)\n",
    "# tokenized_train_dataset = val_dataset.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49dc4e3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 8812\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c8c6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_size = tokenizer.model_max_length\n",
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cbede66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    \n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    \n",
    "    full_length = (total_length // block_size) * block_size\n",
    "    \n",
    "    pad_length = block_size - (total_length - full_length)\n",
    "    \n",
    "    padded_seq = {\n",
    "        'input_ids': concatenated_examples['input_ids'] + ([tokenizer.convert_tokens_to_ids('<PAD>')] * pad_length),\n",
    "        'attention_mask': concatenated_examples['attention_mask'] + ([0] * pad_length)\n",
    "    }\n",
    "    \n",
    "#     print({\n",
    "#         't': total_length,\n",
    "#         'f': full_length,\n",
    "#         'p': pad_length\n",
    "#     })\n",
    "    \n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length + pad_length, block_size)]\n",
    "        for k, t in padded_seq.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "02523812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    print(len(result['input_ids']))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aa3fd17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53584459f884e49a891b3f0f96ea81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****171355*****\n",
      "{'t': 171355, 'f': 171264, 'p': 37}\n",
      "0\n",
      "1339\n",
      "*****168156*****\n",
      "{'t': 168156, 'f': 168064, 'p': 36}\n",
      "0\n",
      "1314\n",
      "*****176735*****\n",
      "{'t': 176735, 'f': 176640, 'p': 33}\n",
      "0\n",
      "1381\n",
      "*****177345*****\n",
      "{'t': 177345, 'f': 177280, 'p': 63}\n",
      "0\n",
      "1386\n",
      "*****167881*****\n",
      "{'t': 167881, 'f': 167808, 'p': 55}\n",
      "0\n",
      "1312\n",
      "*****175677*****\n",
      "{'t': 175677, 'f': 175616, 'p': 67}\n",
      "0\n",
      "1373\n",
      "*****175586*****\n",
      "{'t': 175586, 'f': 175488, 'p': 30}\n",
      "0\n",
      "1372\n",
      "*****179179*****\n",
      "{'t': 179179, 'f': 179072, 'p': 21}\n",
      "0\n",
      "1400\n",
      "*****143385*****\n",
      "{'t': 143385, 'f': 143360, 'p': 103}\n",
      "0\n",
      "1121\n"
     ]
    }
   ],
   "source": [
    "lm_datasets = tokenized_train_dataset.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "#     num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "db2e64c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [458,\n",
       "  1436,\n",
       "  50265,\n",
       "  34975,\n",
       "  19894,\n",
       "  351,\n",
       "  20720,\n",
       "  5935,\n",
       "  50265,\n",
       "  11793,\n",
       "  744,\n",
       "  351,\n",
       "  40377,\n",
       "  24314,\n",
       "  290,\n",
       "  4691,\n",
       "  50264,\n",
       "  50266,\n",
       "  31686,\n",
       "  12,\n",
       "  4933,\n",
       "  13754,\n",
       "  11084,\n",
       "  50267,\n",
       "  50258,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'labels': [458,\n",
       "  1436,\n",
       "  50265,\n",
       "  34975,\n",
       "  19894,\n",
       "  351,\n",
       "  20720,\n",
       "  5935,\n",
       "  50265,\n",
       "  11793,\n",
       "  744,\n",
       "  351,\n",
       "  40377,\n",
       "  24314,\n",
       "  290,\n",
       "  4691,\n",
       "  50264,\n",
       "  50266,\n",
       "  31686,\n",
       "  12,\n",
       "  4933,\n",
       "  13754,\n",
       "  11084,\n",
       "  50267,\n",
       "  50258,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259,\n",
       "  50259]}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ff93475f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 11998\n",
       "})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80185d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "603846f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "dataColl = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5e73ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "#     eval_dataset=val_seq,\n",
    "    tokenizer=tokenizer,\n",
    "#     data_collator=dataColl\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8c99d13b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucky/.venvs/bct-major-project-JO5e2uOw/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8812\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3306\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6460/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.venvs/bct-major-project-JO5e2uOw/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1398\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                 if (\n",
      "\u001b[0;32m~/.venvs/bct-major-project-JO5e2uOw/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1984\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/bct-major-project-JO5e2uOw/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/bct-major-project-JO5e2uOw/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/bct-major-project-JO5e2uOw/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    888\u001b[0m                 )\n\u001b[1;32m    889\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    891\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/bct-major-project-JO5e2uOw/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/bct-major-project-JO5e2uOw/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/bct-major-project-JO5e2uOw/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/bct-major-project-JO5e2uOw/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/bct-major-project-JO5e2uOw/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/bct-major-project-JO5e2uOw/lib/python3.9/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1871\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1872\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d4f628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b3a09179abb8f0db7c6a55d2aaf999af82f90c035207bf7f967fe7ed30ef4e8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
